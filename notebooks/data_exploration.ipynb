{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/local/home/lhauptmann/CV4A/data')\n",
    "data_raw_path = data_path / 'raw'\n",
    "data_processed_path = data_path / 'processed'\n",
    "data_split_path = data_raw_path / 'FieldIds.csv'\n",
    "azcopy_path = '/local/home/lhauptmann/CV4A//local/home/lhauptmann/CV4A/data/azcopy_linux_amd64_10.28.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentinel2_image(image_data, title=\"\", ax = None):\n",
    "    \"\"\"\n",
    "    Plots Sentinel-2 image data (RGB composite or individual bands).\n",
    "\n",
    "    Parameters:\n",
    "        - image_data (numpy array): The image data (RGB composite or individual band).\n",
    "        - title (str): The title of the plot.\n",
    "        - show_colorbar (bool): Whether to show the colorbar. Default is True.\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(image_data, cmap='viridis')\n",
    "    \n",
    "\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.axis('off')  # Turn off axes for better presentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo import datasets\n",
    "import os\n",
    "os.environ[\"PATH\"] = f\"{azcopy_path}:\" + os.environ[\"PATH\"]\n",
    "\n",
    "dataset = datasets.CV4AKenyaCropType(root=data_path/\"raw\", download=True, chip_size = 224, stride=16)\n",
    "\n",
    "split = pd.read_csv(data_split_path)\n",
    "test_id = split[\"test\"].dropna().values\n",
    "train_id = split[\"train\"].dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'mask', 'field_ids', 'tile_index', 'x', 'y']) torch.Size([13, 13, 224, 224])\n",
       "tensor([   0, 1469, 1470, 1689, 1748, 1749, 1750, 1808, 2072, 2345, 2928, 2929,\n",
       "        3180, 3220, 3340, 4034, 4035, 4743, 4775], dtype=torch.int32) tensor([0, 1, 2, 4, 5], dtype=torch.uint8) tensor([0])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = dataset[300]\n",
    "print(sample.keys(), sample[\"image\"].shape)\n",
    "print(sample[\"field_ids\"].unique(), sample[\"mask\"].unique(), sample[\"tile_index\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 13, 224, 224])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Image consists of [n_timepoints, n_bands, height, width]\n",
    "print(sample[\"image\"].shape)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "timepoint = 3\n",
    "plot_sentinel2_image(sample[\"image\"][timepoint,0:-1,...].mean(dim=0), ax = axes[0])\n",
    "plot_sentinel2_image(sample[\"mask\"], ax = axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo import models\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.SENTINEL2_ALL_DECUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'mask', 'field_ids', 'tile_index', 'x', 'y'])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, field_ids, split = [], [], []\n",
    "for sample in dataset:\n",
    "    labels.append(sample[\"mask\"].unique().numpy())\n",
    "    fids = sample[\"field_ids\"].unique().numpy()\n",
    "    field_ids.append(fids)\n",
    "    if all([fid in np.append(test_id, [0]) for fid in fids]) and len(fids) > 1:\n",
    "        split.append(\"test\")\n",
    "    elif all([fid in np.append(train_id, [0]) for fid in fids]) and len(fids) > 1:\n",
    "        split.append(\"train\")\n",
    "    else:\n",
    "        split.append(\"none\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make labels one_hot encoded\n",
    "labels_onehot = []\n",
    "for l in labels:\n",
    "    onehot = np.zeros(8)\n",
    "    onehot[l] = 1\n",
    "    labels_onehot.append(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = np.array(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['train', 'train', 'train', ..., 'train', 'train', 'train'],\n",
       "      shape=(1186,), dtype='<U5'), array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 1., 0., 0.]], shape=(1186, 8)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split[split == \"train\"], np.array(labels_onehot)[split == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import IterativeStratification\n",
    "splits = {}\n",
    "k_fold = IterativeStratification(n_splits=5, order=1)\n",
    "for i, (train, test) in enumerate(k_fold.split(split[split == \"train\"], np.array(labels_onehot)[split == \"train\"])):\n",
    "    splits[i] = {\"train\": train, \"test\": test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"/local/home/lhauptmann/.vscode-server/extensions/ms-python.python-2025.0.0-linux-x64/python_files/python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "  File \"<string>\", line 1, in <module>\n",
       "AttributeError: 'list' object has no attribute 'astype'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_id = np.array(test_id).astype(int).tolist()\n",
    "train_id = np.array(splits[0].get(\"train\")).astype(int).tolist()\n",
    "val_id = np.array(splits[0].get(\"test\")).astype(int).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = [dataset[i] for i in train_id]\n",
    "test_samples = [dataset[i] for i in test_id]\n",
    "val_samples = [dataset[i] for i in val_id]\n",
    "\n",
    "for val_sample in val_samples:\n",
    "    val_sample[\"image\"] = process_images(val_sample[\"image\"])\n",
    "\n",
    "for train_sample in train_samples:\n",
    "    train_sample[\"image\"] = process_images(train_sample[\"image\"])\n",
    "\n",
    "for test_sample in test_samples:\n",
    "    test_sample[\"image\"] = process_images(test_sample[\"image\"])\n",
    "\n",
    "\n",
    "# save as torch dataset\n",
    "import torch\n",
    "\n",
    "torch.save(train_samples, data_processed_path / \"train_samples.pt\")\n",
    "torch.save(test_samples, data_processed_path / \"test_samples.pt\")\n",
    "torch.save(val_samples, data_processed_path / \"val_samples.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 13, 224, 224])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_images(image):\n",
    "    image[:,-1,...] = image[:,-1,...] / 100\n",
    "    image_band = image[:,:-1,...]\n",
    "    image_bands_mean, image_band_std = image_band.mean(dim=(0,2,3),  keepdims=True), image_band.std(dim=(0,2,3), keepdims=True)\n",
    "    image_band_min = image_bands_mean - image_band_std * 2\n",
    "    image_band_max = image_bands_mean + image_band_std * 2\n",
    "    image_band_norm = (image_band - image_band_min) / (image_band_max - image_band_min)\n",
    "    image_band_norm = image_band_norm.clamp(0, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0000e-14)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masks[8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
